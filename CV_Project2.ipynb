{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install gradio opencv-python numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMi5nCc512ex",
        "outputId": "3bed7ae2-1bad-4914-cfb9-86af211277a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ======================= Filters =======================\n",
        "\n",
        "def is_grayscale(img):\n",
        "    return len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1 or np.array_equal(img[..., 0], img[..., 1]) and np.array_equal(img[..., 1], img[..., 2]))\n",
        "\n",
        "def to_gray(img):\n",
        "    if is_grayscale(img):\n",
        "        return img if len(img.shape) == 2 else cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def add_noise(img):\n",
        "    return np.clip(img + np.random.normal(0, 20, img.shape), 0, 255).astype(np.uint8)\n",
        "\n",
        "def salt_pepper_noise(img):\n",
        "    out = np.copy(img)\n",
        "    amount = 0.02\n",
        "    num_salt = np.ceil(amount * img.size * 0.5)\n",
        "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in img.shape[:2]]\n",
        "    out[coords[0], coords[1]] = 255\n",
        "\n",
        "    num_pepper = np.ceil(amount * img.size * 0.5)\n",
        "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in img.shape[:2]]\n",
        "    out[coords[0], coords[1]] = 0\n",
        "    return out\n",
        "\n",
        "def remove_noise(img): return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
        "def mean_filter(img): return cv2.blur(img, (5, 5))\n",
        "def median_filter(img): return cv2.medianBlur(img, 5)\n",
        "def gaussian_filter(img): return cv2.GaussianBlur(img, (5, 5), 0)\n",
        "def erosion(img): return cv2.erode(img, np.ones((5,5),np.uint8), iterations=1)\n",
        "def dilation(img): return cv2.dilate(img, np.ones((5,5),np.uint8), iterations=1)\n",
        "def opening(img): return cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5,5),np.uint8))\n",
        "def closing(img): return cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
        "\n",
        "def boundary_extraction(img):\n",
        "    gray = to_gray(img)\n",
        "    erosion_img = cv2.erode(gray, np.ones((3,3), np.uint8), iterations=1)\n",
        "    boundary = cv2.subtract(gray, erosion_img)\n",
        "    return cv2.cvtColor(boundary, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "def region_filling(img):\n",
        "    gray = to_gray(img)\n",
        "    _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "    im_floodfill = th.copy()\n",
        "    h, w = th.shape[:2]\n",
        "    mask = np.zeros((h+2, w+2), np.uint8)\n",
        "    cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
        "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
        "    filled = th | im_floodfill_inv\n",
        "    return cv2.cvtColor(filled, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "def global_threshold(img):\n",
        "    gray = to_gray(img)\n",
        "    _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "def adaptive_threshold(img):\n",
        "    gray = to_gray(img)\n",
        "    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                               cv2.THRESH_BINARY, 11, 2)\n",
        "    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "def otsu_threshold(img):\n",
        "    gray = to_gray(img)\n",
        "    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "def hough_transform(img):\n",
        "    gray = to_gray(img)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=50, maxLineGap=10)\n",
        "    result = img.copy()\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1,y1,x2,y2 = line[0]\n",
        "            cv2.line(result, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "    return result\n",
        "\n",
        "def watershed_segment(img):\n",
        "    gray = to_gray(img)\n",
        "    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2,5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers+1\n",
        "    markers[unknown==255] = 0\n",
        "    markers = cv2.watershed(img, markers)\n",
        "    img[markers == -1] = [255,0,0]\n",
        "    return img\n",
        "\n",
        "def edge_detection(img):\n",
        "    gray = to_gray(img)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# ========== Filters Map ==========\n",
        "\n",
        "filters_map = {\n",
        "    \"Add Noise\": add_noise,\n",
        "    \"Salt & Pepper Noise\": salt_pepper_noise,\n",
        "    \"Remove Noise\": remove_noise,\n",
        "    \"Mean Filter\": mean_filter,\n",
        "    \"Median Filter\": median_filter,\n",
        "    \"Gaussian Filter\": gaussian_filter,\n",
        "    \"Erosion\": erosion,\n",
        "    \"Dilation\": dilation,\n",
        "    \"Opening\": opening,\n",
        "    \"Closing\": closing,\n",
        "    \"Boundary Extraction\": boundary_extraction,\n",
        "    \"Region Filling\": region_filling,\n",
        "    \"Global Threshold\": global_threshold,\n",
        "    \"Adaptive Threshold\": adaptive_threshold,\n",
        "    \"Otsu Threshold\": otsu_threshold,\n",
        "    \"Hough Transform\": hough_transform,\n",
        "    \"Watershed\": watershed_segment,\n",
        "    \"Edges\": edge_detection\n",
        "}\n",
        "\n",
        "# ========== Apply Selected Filters ==========\n",
        "\n",
        "def apply_selected_filters(img, filters):\n",
        "    if img is None or not filters:\n",
        "        return img\n",
        "    output = img.copy()\n",
        "    for f in filters:\n",
        "        func = filters_map.get(f)\n",
        "        if func:\n",
        "            output = func(output)\n",
        "    return output\n",
        "\n",
        "# ========== Save Image ==========\n",
        "\n",
        "def save_image(img):\n",
        "    path = \"filtered_image.png\"\n",
        "    cv2.imwrite(path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "    return path\n",
        "\n",
        "# ========== Gradio Interface ==========\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\")) as demo:\n",
        "    gr.Markdown(\"## 🎨 Interactive Image Filter Application\")\n",
        "\n",
        "    selected_filters = gr.State([])\n",
        "    button_states = gr.State({})\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(type=\"numpy\", label=\"Original Image\")\n",
        "        output_img = gr.Image(type=\"numpy\", label=\"Filtered Image\")\n",
        "\n",
        "    gr.Markdown(\"### 🧰 Choose Filters\")\n",
        "    filter_buttons = {}\n",
        "    with gr.Row():\n",
        "        for name in filters_map:\n",
        "            btn = gr.Button(value=name, elem_id=f\"btn_{name}\")\n",
        "            filter_buttons[name] = btn\n",
        "\n",
        "    selected_text = gr.Textbox(label=\"Selected Filters\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        apply_btn = gr.Button(\"✅ Apply All Filters\")\n",
        "        reset_btn = gr.Button(\"🔁 Reset All\")\n",
        "        clear_btn = gr.Button(\"🧹 Clear Image & Filters\")\n",
        "\n",
        "    download_file = gr.File(label=\"📥 Download Image\")\n",
        "\n",
        "    def toggle_filter(name, current_filters, btn_states):\n",
        "        new_filters = current_filters.copy()\n",
        "        new_states = btn_states.copy()\n",
        "        if name in new_filters:\n",
        "            new_filters.remove(name)\n",
        "            new_states[name] = \"secondary\"\n",
        "        else:\n",
        "            new_filters.append(name)\n",
        "            new_states[name] = \"primary\"\n",
        "        return new_filters, \", \".join(new_filters), new_states\n",
        "\n",
        "    for fname, btn in filter_buttons.items():\n",
        "        btn.click(fn=toggle_filter,\n",
        "                  inputs=[gr.Text(fname, visible=False), selected_filters, button_states],\n",
        "                  outputs=[selected_filters, selected_text, button_states])\n",
        "\n",
        "    def update_button_colors(btn_states):\n",
        "        updates = {}\n",
        "        for name, variant in btn_states.items():\n",
        "            updates[filter_buttons[name]] = gr.update(variant=variant)\n",
        "        return updates\n",
        "\n",
        "    button_states.change(fn=update_button_colors, inputs=button_states,\n",
        "                         outputs=[*filter_buttons.values()])\n",
        "\n",
        "    apply_btn.click(fn=apply_selected_filters, inputs=[input_img, selected_filters], outputs=output_img)\n",
        "    apply_btn.click(fn=save_image, inputs=output_img, outputs=download_file)\n",
        "\n",
        "    def reset_all(img):\n",
        "        return img, [], \"\", {name: \"secondary\" for name in filters_map}\n",
        "\n",
        "    reset_btn.click(fn=reset_all, inputs=input_img,\n",
        "                    outputs=[output_img, selected_filters, selected_text, button_states])\n",
        "\n",
        "    def clear_all():\n",
        "        return None, None, [], \"\", {name: \"secondary\" for name in filters_map}\n",
        "\n",
        "    clear_btn.click(fn=clear_all,\n",
        "                    outputs=[input_img, output_img, selected_filters, selected_text, button_states])\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "fd_AHAXk19tq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "fafae84e-a35e-4bd0-a099-1f21f2eaca06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://70acdba5caa7251d3d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://70acdba5caa7251d3d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio as gr\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # ======================= Filters =======================\n",
        "# def add_noise(img):\n",
        "#     return np.clip(img + np.random.normal(0, 20, img.shape), 0, 255).astype(np.uint8)\n",
        "\n",
        "# def salt_pepper_noise(img):\n",
        "#     out = np.copy(img)\n",
        "#     amount = 0.02\n",
        "#     num_salt = np.ceil(amount * img.size * 0.5)\n",
        "#     coords = [np.random.randint(0, i - 1, int(num_salt)) for i in img.shape[:2]]\n",
        "#     out[coords[0], coords[1]] = 255\n",
        "\n",
        "#     num_pepper = np.ceil(amount * img.size * 0.5)\n",
        "#     coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in img.shape[:2]]\n",
        "#     out[coords[0], coords[1]] = 0\n",
        "#     return out\n",
        "\n",
        "# def remove_noise(img): return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
        "# def mean_filter(img): return cv2.blur(img, (5, 5))\n",
        "# def median_filter(img): return cv2.medianBlur(img, 5)\n",
        "# def gaussian_filter(img): return cv2.GaussianBlur(img, (5, 5), 0)\n",
        "# def erosion(img): return cv2.erode(img, np.ones((5,5),np.uint8), iterations=1)\n",
        "# def dilation(img): return cv2.dilate(img, np.ones((5,5),np.uint8), iterations=1)\n",
        "# def opening(img): return cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5,5),np.uint8))\n",
        "# def closing(img): return cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
        "\n",
        "# def boundary_extraction(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     erosion_img = cv2.erode(gray, np.ones((3,3), np.uint8), iterations=1)\n",
        "#     boundary = cv2.subtract(gray, erosion_img)\n",
        "#     return cv2.cvtColor(boundary, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# def region_filling(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "#     im_floodfill = th.copy()\n",
        "#     h, w = th.shape[:2]\n",
        "#     mask = np.zeros((h+2, w+2), np.uint8)\n",
        "#     cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
        "#     im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
        "#     filled = th | im_floodfill_inv\n",
        "#     return cv2.cvtColor(filled, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# def global_threshold(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "#     return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# def adaptive_threshold(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "#                                cv2.THRESH_BINARY, 11, 2)\n",
        "#     return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# def otsu_threshold(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "#     return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# def hough_transform(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     edges = cv2.Canny(gray, 50, 150)\n",
        "#     lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=50, maxLineGap=10)\n",
        "#     result = img.copy()\n",
        "#     if lines is not None:\n",
        "#         for line in lines:\n",
        "#             x1,y1,x2,y2 = line[0]\n",
        "#             cv2.line(result, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "#     return result\n",
        "\n",
        "# def watershed_segment(img):\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "#     kernel = np.ones((3,3),np.uint8)\n",
        "#     opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "#     sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "#     dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2,5)\n",
        "#     _, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
        "#     sure_fg = np.uint8(sure_fg)\n",
        "#     unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "#     _, markers = cv2.connectedComponents(sure_fg)\n",
        "#     markers = markers+1\n",
        "#     markers[unknown==255] = 0\n",
        "#     markers = cv2.watershed(img, markers)\n",
        "#     img[markers == -1] = [255,0,0]\n",
        "#     return img\n",
        "\n",
        "# # ========== Filters Map ==========\n",
        "# filters_map = {\n",
        "#     \"Add Noise\": add_noise,\n",
        "#     \"Salt & Pepper Noise\": salt_pepper_noise,\n",
        "#     \"Remove Noise\": remove_noise,\n",
        "#     \"Mean Filter\": mean_filter,\n",
        "#     \"Median Filter\": median_filter,\n",
        "#     \"Gaussian Filter\": gaussian_filter,\n",
        "#     \"Erosion\": erosion,\n",
        "#     \"Dilation\": dilation,\n",
        "#     \"Opening\": opening,\n",
        "#     \"Closing\": closing,\n",
        "#     \"Boundary Extraction\": boundary_extraction,\n",
        "#     \"Region Filling\": region_filling,\n",
        "#     \"Global Threshold\": global_threshold,\n",
        "#     \"Adaptive Threshold\": adaptive_threshold,\n",
        "#     \"Otsu Threshold\": otsu_threshold,\n",
        "#     \"Hough Transform\": hough_transform,\n",
        "#     \"Watershed\": watershed_segment\n",
        "# }\n",
        "\n",
        "# # ========== Apply Selected Filters ==========\n",
        "# def apply_selected_filters(img, filters):\n",
        "#     if img is None or not filters:\n",
        "#         return img\n",
        "#     output = img.copy()\n",
        "#     for f in filters:\n",
        "#         func = filters_map.get(f)\n",
        "#         if func:\n",
        "#             output = func(output)\n",
        "#     return output\n",
        "\n",
        "# # ========== Save Image ==========\n",
        "# def save_image(img):\n",
        "#     path = \"filtered_image.png\"\n",
        "#     cv2.imwrite(path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "#     return path\n",
        "\n",
        "# # ========== Gradio Interface ==========\n",
        "# with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\")) as demo:\n",
        "#     gr.Markdown(\"## 🎨 Interactive Image Filter Application\")\n",
        "\n",
        "#     selected_filters = gr.State([])\n",
        "#     button_states = gr.State({})\n",
        "\n",
        "#     with gr.Row():\n",
        "#         input_img = gr.Image(type=\"numpy\", label=\"Original Image\")\n",
        "#         output_img = gr.Image(type=\"numpy\", label=\"Filtered Image\")\n",
        "\n",
        "#     gr.Markdown(\"### 🧰 Choose Filters\")\n",
        "#     filter_buttons = {}\n",
        "#     with gr.Row():\n",
        "#         for name in filters_map:\n",
        "#             btn = gr.Button(value=name, elem_id=f\"btn_{name}\")\n",
        "#             filter_buttons[name] = btn\n",
        "\n",
        "#     selected_text = gr.Textbox(label=\"Selected Filters\", interactive=False)\n",
        "\n",
        "#     with gr.Row():\n",
        "#         apply_btn = gr.Button(\"✅ Apply All Filters\")\n",
        "#         reset_btn = gr.Button(\"🔁 Reset All\")\n",
        "#         clear_btn = gr.Button(\"🧹 Clear Image & Filters\")\n",
        "\n",
        "#     download_file = gr.File(label=\"📥 Download Image\")\n",
        "\n",
        "#     # ---------- Toggle Button ----------\n",
        "#     def toggle_filter(name, current_filters, btn_states):\n",
        "#         new_filters = current_filters.copy()\n",
        "#         new_states = btn_states.copy()\n",
        "#         if name in new_filters:\n",
        "#             new_filters.remove(name)\n",
        "#             new_states[name] = \"secondary\"\n",
        "#         else:\n",
        "#             new_filters.append(name)\n",
        "#             new_states[name] = \"primary\"\n",
        "#         return new_filters, \", \".join(new_filters), new_states\n",
        "\n",
        "#     for fname, btn in filter_buttons.items():\n",
        "#         btn.click(fn=toggle_filter,\n",
        "#                   inputs=[gr.Text(fname, visible=False), selected_filters, button_states],\n",
        "#                   outputs=[selected_filters, selected_text, button_states])\n",
        "\n",
        "#     def update_button_colors(btn_states):\n",
        "#         updates = {}\n",
        "#         for name, variant in btn_states.items():\n",
        "#             updates[filter_buttons[name]] = gr.update(variant=variant)\n",
        "#         return updates\n",
        "\n",
        "#     button_states.change(fn=update_button_colors, inputs=button_states,\n",
        "#                          outputs=[*filter_buttons.values()])\n",
        "\n",
        "#     apply_btn.click(fn=apply_selected_filters, inputs=[input_img, selected_filters], outputs=output_img)\n",
        "#     apply_btn.click(fn=save_image, inputs=output_img, outputs=download_file)\n",
        "\n",
        "#     def reset_all(img):\n",
        "#         return img, [], \"\", {name: \"secondary\" for name in filters_map}\n",
        "\n",
        "#     reset_btn.click(fn=reset_all, inputs=input_img,\n",
        "#                     outputs=[output_img, selected_filters, selected_text, button_states])\n",
        "\n",
        "#     def clear_all():\n",
        "#         return None, None, [], \"\", {name: \"secondary\" for name in filters_map}\n",
        "\n",
        "#     clear_btn.click(fn=clear_all,\n",
        "#                     outputs=[input_img, output_img, selected_filters, selected_text, button_states])\n",
        "\n",
        "# demo.launch()\n"
      ],
      "metadata": {
        "id": "jby60tNJaGr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "f1798a1c-9098-4b6a-9ed5-d50be8a4d1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9fa05fb08b3520192c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fa05fb08b3520192c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}